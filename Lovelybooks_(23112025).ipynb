{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiy8h/8xrg4ojlRvptU7VR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnmarten/utils/blob/main/Lovelybooks_(23112025).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#paste lovelybooks url\n",
        "book_url = 'https://www.lovelybooks.de/autor/Mareike-Fallwickl/Und-alle-so-still-11024743518-w/'"
      ],
      "metadata": {
        "id": "JzrgzemruL3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht1moqNa1oJV"
      },
      "outputs": [],
      "source": [
        "#expanded to include all Lovelybooks text reviews (23.11.2025)\n",
        "# Update package list and install necessary dependencies\n",
        "!apt-get update\n",
        "!apt-get install -y wget unzip libvulkan1\n",
        "\n",
        "# Download and install Google Chrome\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb\n",
        "!apt-get install -f -y\n",
        "\n",
        "# Install xvfb for virtual framebuffer support\n",
        "!apt-get install -y xvfb\n",
        "\n",
        "# Install required packages\n",
        "!pip install selenium chromedriver-autoinstaller beautifulsoup4 pandas\n",
        "\n",
        "# Automatically install the correct version of ChromeDriver\n",
        "import chromedriver_autoinstaller\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Configure Selenium with obfuscation for headless mode\n",
        "def configure_driver():\n",
        "    options = Options()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    options.add_argument('--remote-debugging-port=9222')\n",
        "    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
        "\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    # Execute CDP commands to hide automation\n",
        "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\n",
        "        \"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
        "    })\n",
        "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
        "\n",
        "    return driver\n",
        "\n",
        "# Scrape reviews and metadata from a LovelyBooks.de book page\n",
        "def scrape_reviews(book_url):\n",
        "    driver = configure_driver()\n",
        "    driver.get(book_url)\n",
        "    reviews = []\n",
        "    metadata = {}\n",
        "\n",
        "    try:\n",
        "        # Wait for page to load\n",
        "        time.sleep(3)\n",
        "\n",
        "        # Extract metadata - correct title selector\n",
        "        try:\n",
        "            title_elem = driver.find_element(By.CSS_SELECTOR, '.BookTitle__Title-lxryhc-1')\n",
        "            metadata['title'] = title_elem.text\n",
        "            print(f\"Found title: {metadata['title']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not find title: {e}\")\n",
        "            metadata['title'] = 'Unknown'\n",
        "\n",
        "        # Extract subtitle if available\n",
        "        try:\n",
        "            subtitle_elem = driver.find_element(By.CSS_SELECTOR, '.BookTitle__Subtitle-lxryhc-2')\n",
        "            metadata['subtitle'] = subtitle_elem.text\n",
        "        except:\n",
        "            metadata['subtitle'] = ''\n",
        "\n",
        "        # Extract author\n",
        "        try:\n",
        "            author_links = driver.find_elements(By.CSS_SELECTOR, '.BookInfos__AuthorLinkWrap-sc-13pbtxl-2 a')\n",
        "            if author_links:\n",
        "                metadata['author'] = author_links[-1].text  # Get last author link (actual author name)\n",
        "        except:\n",
        "            metadata['author'] = 'Unknown'\n",
        "\n",
        "        page_count = 0\n",
        "        previous_review_count = 0\n",
        "\n",
        "        # Loop through all review pages\n",
        "        while True:\n",
        "            page_count += 1\n",
        "            print(f\"\\n--- Processing page {page_count} ---\")\n",
        "\n",
        "            # Wait for reviews to load\n",
        "            try:\n",
        "                WebDriverWait(driver, 10).until(\n",
        "                    EC.presence_of_element_located((By.CSS_SELECTOR, '.StreamEntry, .style__EntryContent-sc-1aphc73-11, article[class*=\"ReviewAndReviewShortQuoteStreamItem\"]'))\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"No reviews found on page: {e}\")\n",
        "                break\n",
        "\n",
        "            # Get page source and parse with BeautifulSoup\n",
        "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "            # Find all review entries - try multiple selectors\n",
        "            review_entries = soup.select('article[class*=\"ReviewAndReviewShortQuoteStreamItem\"], article.style__ReviewAndReviewShortQuoteStreamItem-sc-1aphc73-0')\n",
        "\n",
        "            if len(review_entries) == 0:\n",
        "                review_entries = soup.select('.StreamEntry, [class*=\"StreamEntry\"]')\n",
        "\n",
        "            if len(review_entries) == 0:\n",
        "                review_entries = soup.select('[class*=\"style__EntryContent\"]')\n",
        "\n",
        "            print(f\"Found {len(review_entries)} review entries on this page\")\n",
        "\n",
        "            if len(review_entries) == 0:\n",
        "                print(\"No reviews found, stopping...\")\n",
        "                break\n",
        "\n",
        "            # Track reviews added from this page\n",
        "            reviews_added_this_page = 0\n",
        "\n",
        "            for idx, entry in enumerate(review_entries, 1):\n",
        "                try:\n",
        "                    # Extract author\n",
        "                    author = None\n",
        "                    author_elem = entry.select_one('[class*=\"UsernameLink\"], .UserLink__TextOnly-sc-5ioweh-1, a[class*=\"UsernameLink\"]')\n",
        "                    if author_elem:\n",
        "                        author = author_elem.get_text(strip=True)\n",
        "\n",
        "                    # Extract datetime\n",
        "                    datetime = None\n",
        "                    time_elem = entry.select_one('time')\n",
        "                    if time_elem:\n",
        "                        datetime = time_elem.get('datetime', time_elem.get_text(strip=True))\n",
        "\n",
        "                    # Extract star rating\n",
        "                    star_rating = 0\n",
        "                    star_elements = entry.select('.CommonIcon.-star-full, [class*=\"CommonIcon\"].-star-full')\n",
        "                    star_rating = len(star_elements)\n",
        "\n",
        "                    # Extract short review (Kurzmeinung)\n",
        "                    short_review = None\n",
        "                    quote_elem = entry.select_one('.Quote__Paragraph-ukhk62-0, [class*=\"Quote__Paragraph\"]')\n",
        "                    if quote_elem:\n",
        "                        short_review = quote_elem.get_text(strip=True)\n",
        "\n",
        "                    # Extract full review\n",
        "                    full_review = None\n",
        "                    review_elem = entry.select_one('.HtmlBox, [class*=\"HtmlBox\"]')\n",
        "                    if review_elem:\n",
        "                        full_review = review_elem.get_text(strip=True)\n",
        "\n",
        "                    # Only add if we have some content and haven't seen this review before\n",
        "                    if (author or short_review or full_review):\n",
        "                        # Create a unique identifier for the review to avoid duplicates\n",
        "                        review_id = f\"{author}_{datetime}_{star_rating}\"\n",
        "\n",
        "                        # Check if we already have this review\n",
        "                        if not any(r.get('review_id') == review_id for r in reviews):\n",
        "                            reviews.append({\n",
        "                                'review_id': review_id,\n",
        "                                'author': author,\n",
        "                                'datetime': datetime,\n",
        "                                'star_rating': star_rating,\n",
        "                                'short_review': short_review,\n",
        "                                'full_review': full_review,\n",
        "                                'page': page_count\n",
        "                            })\n",
        "                            reviews_added_this_page += 1\n",
        "                            print(f\"  ✓ Review {len(reviews)}: {author} - {star_rating} stars\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ✗ Error extracting review {idx}: {e}\")\n",
        "\n",
        "            print(f\"Added {reviews_added_this_page} new reviews from this page (Total: {len(reviews)})\")\n",
        "\n",
        "            # Check if we're getting new reviews\n",
        "            if len(reviews) == previous_review_count:\n",
        "                print(\"No new reviews found on this page, stopping...\")\n",
        "                break\n",
        "\n",
        "            previous_review_count = len(reviews)\n",
        "\n",
        "            # Try to find and click the 'Weitere Beiträge laden' button\n",
        "            button_clicked = False\n",
        "\n",
        "            # Try multiple selector strategies\n",
        "            selectors = [\n",
        "                'button.moreButton',\n",
        "                'button.-outlined.moreButton',\n",
        "                'button[class*=\"moreButton\"]',\n",
        "                'button.Button.-outlined.moreButton',\n",
        "                '.separator button',\n",
        "                'button:contains(\"Weitere Beiträge laden\")'\n",
        "            ]\n",
        "\n",
        "            for selector in selectors:\n",
        "                try:\n",
        "                    # Wait for button to be present\n",
        "                    load_more_button = WebDriverWait(driver, 5).until(\n",
        "                        EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
        "                    )\n",
        "\n",
        "                    print(f\"Found button with selector: {selector}\")\n",
        "\n",
        "                    # Scroll to button\n",
        "                    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", load_more_button)\n",
        "                    time.sleep(1)\n",
        "\n",
        "                    # Wait for button to be clickable\n",
        "                    load_more_button = WebDriverWait(driver, 5).until(\n",
        "                        EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n",
        "                    )\n",
        "\n",
        "                    # Try JavaScript click first (more reliable)\n",
        "                    driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
        "                    print(f\"Clicked 'Weitere Beiträge laden' button using JavaScript\")\n",
        "\n",
        "                    button_clicked = True\n",
        "                    time.sleep(3)  # Wait for new content to load\n",
        "                    break\n",
        "\n",
        "                except Exception as e:\n",
        "                    # Try next selector\n",
        "                    continue\n",
        "\n",
        "            # If no button found with any selector, try finding by text\n",
        "            if not button_clicked:\n",
        "                try:\n",
        "                    # Try XPath to find button by text\n",
        "                    load_more_button = WebDriverWait(driver, 5).until(\n",
        "                        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Weitere Beiträge laden')]\"))\n",
        "                    )\n",
        "\n",
        "                    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", load_more_button)\n",
        "                    time.sleep(1)\n",
        "                    driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
        "                    print(\"Clicked 'Weitere Beiträge laden' button using XPath\")\n",
        "                    button_clicked = True\n",
        "                    time.sleep(3)\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not find load more button: {e}\")\n",
        "\n",
        "            if not button_clicked:\n",
        "                print(\"No more pages to load - button not found\")\n",
        "                break\n",
        "\n",
        "            # Safety limit\n",
        "            if page_count >= 50:\n",
        "                print(\"Reached page limit of 50\")\n",
        "                break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping reviews: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "    # Remove review_id from final output\n",
        "    for review in reviews:\n",
        "        review.pop('review_id', None)\n",
        "\n",
        "    return metadata, reviews\n",
        "\n",
        "# Save reviews to a CSV file\n",
        "def save_reviews_to_csv(metadata, reviews, output_file='lovelybooks_reviews.csv'):\n",
        "    if not reviews:\n",
        "        print(\"No reviews to save!\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame(reviews)\n",
        "    df['book_title'] = metadata.get('title', '')\n",
        "    df['book_subtitle'] = metadata.get('subtitle', '')\n",
        "    df['book_author'] = metadata.get('author', '')\n",
        "\n",
        "    # Reorder columns\n",
        "    cols = ['book_title', 'book_subtitle', 'book_author', 'author', 'datetime',\n",
        "            'star_rating', 'short_review', 'full_review', 'page']\n",
        "    df = df[cols]\n",
        "\n",
        "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
        "    print(f\"\\n✓ Saved {len(reviews)} reviews to {output_file}\")\n",
        "\n",
        "    # Auto-download in Colab\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(output_file)\n",
        "        print(f\"  ⬇ Downloaded {output_file}\")\n",
        "    except:\n",
        "        print(f\"  (Not in Colab environment - file saved locally)\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Main script\n",
        "if __name__ == '__main__':\n",
        "    # Example book URL\n",
        "    #book_url = 'https://www.lovelybooks.de/autor/Mareike-Fallwickl/Und-alle-so-still-11024743518-w/'\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"LOVELYBOOKS REVIEW SCRAPER\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nScraping: {book_url}\\n\")\n",
        "\n",
        "    metadata, reviews = scrape_reviews(book_url)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Book: {metadata.get('title', 'Unknown')}\")\n",
        "    print(f\"Author: {metadata.get('author', 'Unknown')}\")\n",
        "    print(f\"Total reviews scraped: {len(reviews)}\")\n",
        "\n",
        "    if reviews:\n",
        "        df = save_reviews_to_csv(metadata, reviews)\n",
        "        print(\"\\nFirst few reviews:\")\n",
        "        print(df[['author', 'star_rating', 'short_review']].head())\n",
        "    else:\n",
        "        print(\"\\nNo reviews found!\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DONE!\")\n",
        "    print(\"=\"*60)"
      ]
    }
  ]
}