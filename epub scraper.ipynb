{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epub is a hidden zip file; change epub ending to zip and unpack into a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#may have to install packages with pip\n",
    "# in Colab use !pip install bs4\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id})\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'bachmannfrisch' #name of the subfolder in the folder containing the script \n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(x.split('.')[0])):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not all of these cells are necessary and in the right order, this was used to work towards solving specific problems\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for file_id in sorted([int(re.findall(r'\\d+', filename)[0]) for filename in os.listdir(folder_path) if filename.endswith('.html')]):\n",
    "    filename = f\"{file_id}.html\"\n",
    "    filepath = os.path.join(folder_path, filename)\n",
    "    print(f\"Processing {filepath}\")\n",
    "    data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we worked to retrieve specific spans within the html, customize according to your own data\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+(?=\\.)', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id})\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+(?=\\.)', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that 'df' is the name of the DataFrame\n",
    "row_index = 225 # The index of the row to display\n",
    "column_name = 'date' # The name of the column to display\n",
    "\n",
    "# Use .loc to select the row of interest and access the value of the column\n",
    "text = df.loc[row_index, column_name]\n",
    "\n",
    "# Print the complete text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colName in df.columns:\n",
    "    if colName == \"date\":\n",
    "        df = df[ df[colName].notna() ]\n",
    "    else:\n",
    "        df = df[ df[colName].isna() ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv', encoding='utf-8') #writing the resulting dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract date from <p class=\"brief_datum\"> tag\n",
    "                date_tag = soup.find('p', {'class': 'brief_datum'})\n",
    "                if date_tag:\n",
    "                    date_text = date_tag.text.strip()\n",
    "                    # extract date using regex\n",
    "                    match = re.search(r'(\\d+[\\s\\.-]*\\w*[\\s\\.-]*\\d+)', date_text)\n",
    "                    if match:\n",
    "                        date_str = match.group().replace('.', '').replace('-', '').replace(' ', '.')\n",
    "                        try:\n",
    "                            date = datetime.strptime(date_str, '%d.%m.%Y').date()\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                date = datetime.strptime(date_str, '%d.%m.%y').date()\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    date = datetime.strptime(date_str, '%d.%B.%Y').date()\n",
    "                                except ValueError:\n",
    "                                    date = 'NA'\n",
    "                    else:\n",
    "                        date = 'NA'\n",
    "                else:\n",
    "                    date = 'NA'\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id, 'date': date})\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "#for filename in sorted(os.listdir(folder_path), key=lambda x: int(x.split('.')[0])):\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+(?=\\.)', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "        \n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract date from <p class=\"brief_datum\"> tag\n",
    "                date_tags = p_tag.find_all('p', {'class': 'brief_datum'})\n",
    "                dates = []\n",
    "                for date_tag in date_tags:\n",
    "                    date_text = date_tag.text.strip()\n",
    "                    # regex to match various date formats in German\n",
    "                    match = re.search(r'\\b(\\d{1,2})([^\\d]+)(\\d{1,2})([^\\d]+)(\\d{2,4})\\b', date_text)\n",
    "                    if match:\n",
    "                        date_str = match.group(0)\n",
    "                        try:\n",
    "                            # convert to datetime object\n",
    "                            date = datetime.strptime(date_str, '%d.%m.%Y').date()\n",
    "                            dates.append(date)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "                    else:\n",
    "                        dates.append(None)\n",
    "                # create dictionary of data for this HTML file\n",
    "                data_dict = {'id': id, 'title': title, 'letter_text': letter_text, 'file_id': int(re.search(r'\\d+', filepath).group())}\n",
    "                # add date to dictionary\n",
    "                if len(dates) == 0:\n",
    "                    data_dict['date'] = None\n",
    "                elif len(dates) == 1:\n",
    "                    data_dict['date'] = dates[0]\n",
    "                else:\n",
    "                    # choose the earliest date as the main date\n",
    "                    data_dict['date'] = min(dates)\n",
    "                data.append(data_dict)\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                \n",
    "                # extract datum from <p> tag\n",
    "                datum_tags = p_tag.find_next_siblings('p', {'class': 'brief_datum'})\n",
    "                datum_values = []\n",
    "                for datum_tag in datum_tags:\n",
    "                    datum_text = datum_tag.text.strip()\n",
    "                    if re.match(r'^\\d{1,2}\\.?\\s*[-.,/\\\\]?\\s*\\d{1,2}\\.?\\s*[-.,/\\\\]?\\s*\\d{2,4}$', datum_text):\n",
    "                        try:\n",
    "                            datum_value = datetime.strptime(datum_text, '%d.%m.%Y').date()\n",
    "                            datum_values.append(datum_value)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "                    elif re.match(r'^\\d{1,2}\\s*[-.,/\\\\]?\\s*\\w+\\s+\\d{4}$', datum_text):\n",
    "                        try:\n",
    "                            datum_value = datetime.strptime(datum_text, '%d. %B %Y').date()\n",
    "                            datum_values.append(datum_value)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "                    elif re.match(r'^[A-Za-z]+\\s*,?\\s*\\d{1,2}\\.?\\s*[-.,/\\\\]?\\s*\\d{1,2}\\.?\\s*[-.,/\\\\]?\\s*\\d{2,4}$', datum_text):\n",
    "                        datum_value = re.search(r'\\d{1,2}\\.?\\s*[-.,/\\\\]?\\s*\\d{1,2}\\.?\\s*[-.,/\\\\]?\\s*\\d{2,4}', datum_text).group(0)\n",
    "                        try:\n",
    "                            datum_value = datetime.strptime(datum_value, '%d.%m.%Y').date()\n",
    "                            datum_values.append(datum_value)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "                if datum_values:\n",
    "                    datum = datum_values[0]\n",
    "                else:\n",
    "                    datum = \"NA\"\n",
    "                \n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id, 'datum': datum})\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "#for filename in sorted(os.listdir(folder_path), key=lambda x:\n",
    "# loop over all HTML files in a folder and extract information\n",
    "#folder_path = 'bachmannfrisch'\n",
    "#data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                # extract date from <p> tag\n",
    "                datum_tags = soup.find_all('p', {'class': 'brief_datum'})\n",
    "                datum = None\n",
    "                for datum_tag in datum_tags:\n",
    "                    datum_text = datum_tag.get_text().strip()\n",
    "                    # extract date from text using regex\n",
    "                    match = re.search(r'(\\d{1,2})[\\.\\s-]+([\\wäöü]+)[\\s-]+(\\d{2,4})', datum_text)\n",
    "                    if match:\n",
    "                        # convert to date object\n",
    "                        try:\n",
    "                            datum = datetime.strptime(match.group(), '%d. %B %Y').date()\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                datum = datetime.strptime(match.group(), '%d.%m.%Y').date()\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    datum = datetime.strptime(match.group(), '%d-%m-%Y').date()\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "                        break\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id, 'datum': datum})\n",
    "                print(f\"Processed id {id}: title='{title}', letter_text='{letter_text}', file_id={file_id}, datum={datum}\")\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                \n",
    "                # extract date from <p> tag\n",
    "                datum_tags = p_tag.find_all('p', {'class': 'brief_datum'})\n",
    "                date = None\n",
    "                for datum_tag in datum_tags:\n",
    "                    datum_str = datum_tag.text.strip()\n",
    "                    # match various date formats in German\n",
    "                    match = re.search(r'(\\d{1,2}\\s*[.-]\\s*\\w+\\s*[.-]\\s*\\d{2,4}|\\d{1,2}\\s*[.-]\\s*\\d{1,2}\\s*[.-]\\s*\\d{2,4}|\\w+\\s+\\d{1,2},\\s*\\d{2,4})', datum_str)\n",
    "                    if match:\n",
    "                        date_str = match.group()\n",
    "                        try:\n",
    "                            date = datetime.strptime(date_str, '%d.%m.%Y').date()\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                date = datetime.strptime(date_str, '%d-%m-%Y').date()\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    date = datetime.strptime(date_str, '%d %b %Y').date()\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "                    if date:\n",
    "                        break\n",
    "                \n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id, 'date': date})\n",
    "        return data\n",
    "\n",
    "# loop over all\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                # extract date from <p> tag\n",
    "                datum_tags = p_tag.find_all('p', {'class': 'brief_datum'})\n",
    "                date = None\n",
    "                for datum_tag in datum_tags:\n",
    "                    datum_text = datum_tag.text.strip()\n",
    "                    try:\n",
    "                        date = parse(datum_text, dayfirst=True)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'date': date, 'file_id': file_id})\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "\n",
    "                # extract date from <p class=\"brief_datum\"> tag\n",
    "                datum_tags = p_tag.find_all('p', {'class': 'brief_datum'})\n",
    "                datum = None\n",
    "                if datum_tags:\n",
    "                    for tag in datum_tags:\n",
    "                        # Check if the text inside the tag resembles a date\n",
    "                        try:\n",
    "                            parse(tag.text.strip(), dayfirst=True, yearfirst=False)\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                        datum = tag.text.strip()\n",
    "                        break\n",
    "\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id, 'datum': datum})\n",
    "\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                # extract brief_datum from <p> tag most resembling a date\n",
    "                datum_tags = div_tag.find_all('p', {'class': 'brief_datum'})\n",
    "                if datum_tags:\n",
    "                    datum_text = \"\"\n",
    "                    for datum_tag in datum_tags:\n",
    "                        datum_text = datum_tag.text.strip()\n",
    "                        if re.match(r'\\d+\\.\\s*[\\d\\w]+\\s*\\d+', datum_text):\n",
    "                            break\n",
    "                    else:\n",
    "                        datum_text = \"NA\"\n",
    "                else:\n",
    "                    datum_text = \"NA\"\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id, 'date': datum_text})\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colName in df.columns:\n",
    "    if colName == \"date\":\n",
    "        df = df[ df[colName].notna() ]\n",
    "    else:\n",
    "        df = df[ df[colName].isna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                # extract date from brief_datum tag\n",
    "                datum_tags = div_tag.find_all('p', {'class': 'brief_datum'})\n",
    "                if datum_tags:\n",
    "                    datum_text = datum_tags[-1].text.strip()\n",
    "                    if re.match(r'\\d+\\.\\s*\\w+\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d. %B %Y')\n",
    "                    elif re.match(r'\\d+\\s*-\\s*\\d+\\s*-\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d - %m - %Y')\n",
    "                    elif re.match(r'\\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d.%m.%Y')\n",
    "                    elif re.match(r'\\w+, \\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(re.findall(r'\\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text)[0], '%d.%m.%Y')\n",
    "                    else:\n",
    "                        datum = 'NA'\n",
    "                else:\n",
    "                    datum = 'NA'\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id, 'date': datum})\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                # extract date from brief_datum tag\n",
    "                datum_tags = div_tag.find_all('p', {'class': 'brief_datum'})\n",
    "                if datum_tags:\n",
    "                    datum_text = datum_tags[-1].text.strip().replace('\\xa0', ' ')\n",
    "                    if re.match(r'\\d+\\.\\s*\\w+\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d. %B %Y')\n",
    "                    elif re.match(r'\\d+\\s*-\\s*\\d+\\s*-\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d - %m - %Y')\n",
    "                    elif re.match(r'\\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d.%m.%Y')\n",
    "                    elif re.match(r'\\w+, \\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(re.findall(r'\\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text)[0], '%d.%m.%Y')\n",
    "                    else:\n",
    "                        datum = 'NA'\n",
    "                else:\n",
    "                    datum = 'NA'\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'date': datum})\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                # extract date from brief_datum tag\n",
    "                datum_tags = div_tag.find_all('p', {'class': 'brief_datum'})\n",
    "                if datum_tags:\n",
    "                    datum_text = datum_tags[-1].text.strip().replace('\\xa0', ' ')\n",
    "                    if re.match(r'\\d+\\.\\s*\\w+\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d. %B %Y')\n",
    "                    elif re.match(r'\\d+\\s*-\\s*\\d+\\s*-\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d - %m - %Y')\n",
    "                    elif re.match(r'\\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d.%m.%Y')\n",
    "                    elif re.match(r'\\w+, \\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(re.findall(r'\\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text)[0], '%d.%m.%Y')\n",
    "                    else:\n",
    "                        datum = 'NA'\n",
    "                else:\n",
    "                    datum = 'NA'\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'file_id': file_id, 'date': datum})\n",
    "        return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change locale if colab moans about this\n",
    "import locale\n",
    "#locale.setlocale(locale.LC_TIME, 'de_DE')\n",
    "locale.setlocale(locale.LC_TIME, 'de_DE.utf8')\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=['file_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# define a function to extract information from each HTML file\n",
    "def extract_info(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # extract id and title from <p> tag\n",
    "        p_tags = soup.find_all('p', {'class': 'brief_titel1'})\n",
    "        data = []\n",
    "        for p_tag in p_tags:\n",
    "            id = p_tag.get('id')\n",
    "            title = p_tag.get('title')\n",
    "            # extract letter text from <div> tag\n",
    "            div_tag = p_tag.find_next_sibling('div', {'class': 'letter'})\n",
    "            if div_tag:\n",
    "                letter_text = ''\n",
    "                for p_tag in div_tag.find_all('p'):\n",
    "                    if 'class' in p_tag.attrs and ('gt' in p_tag['class'] or 'brief_gt' in p_tag['class']):\n",
    "                        letter_text += p_tag.text.strip().replace('</p>', ' ') + ' '\n",
    "                # extract numeric portion of filename using regex\n",
    "                match = re.search(r'\\d+', filepath)\n",
    "                if match:\n",
    "                    file_id = int(match.group())\n",
    "                else:\n",
    "                    file_id = None\n",
    "                # extract date from brief_datum tag\n",
    "                datum_tags = div_tag.find_all('p', {'class': 'brief_datum'})\n",
    "                if datum_tags:\n",
    "                    datum_text = datum_tags[-1].text.strip().replace('\\xa0', ' ')\n",
    "                    # convert date string to datetime object\n",
    "                    if re.match(r'\\d+\\.\\s*\\w+\\s*\\d+', datum_text):\n",
    "                        try:\n",
    "                            datum = datetime.strptime(datum_text, '%d. %B %Y')\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                datum = datetime.strptime(datum_text, '%d. %b %Y')\n",
    "                            except ValueError:\n",
    "                                datum = 'NA'\n",
    "                    elif re.match(r'\\d+\\s*-\\s*\\d+\\s*-\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d - %m - %Y')\n",
    "                    elif re.match(r'\\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(datum_text, '%d.%m.%Y')\n",
    "                    elif re.match(r'\\w+, \\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text):\n",
    "                        datum = datetime.strptime(re.findall(r'\\d+\\.\\s*\\d+\\.\\s*\\d+', datum_text)[0], '%d.%m.%Y')\n",
    "                    else:\n",
    "                        datum = 'NA'\n",
    "                else:\n",
    "                    datum = 'NA'\n",
    "                data.append({'id': id, 'title': title, 'letter_text': letter_text, 'date': datum})\n",
    "        return data\n",
    "\n",
    "# loop over all HTML files in a folder and extract information\n",
    "folder_path = 'bachmannfrisch'\n",
    "data = []\n",
    "for filename in sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filepath}\")\n",
    "        data += extract_info(filepath)\n",
    "\n",
    "# create a Pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "#df.drop(columns=['file_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
